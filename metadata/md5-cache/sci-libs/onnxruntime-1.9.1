BDEPEND=>=dev-util/ninja-1.8.2 >=dev-util/cmake-3.20.5
DEFINED_PHASES=compile configure install prepare test
DEPEND=dev-python/numpy dev-libs/date:= >=dev-libs/boost-1.66:= dev-libs/protobuf:= dev-libs/re2:= dev-libs/flatbuffers:= dev-cpp/nlohmann_json:= dev-libs/nsync dev-cpp/eigen:3 benchmark? ( dev-cpp/benchmark ) test? ( dev-cpp/gtest )
DESCRIPTION=cross-platform, high performance ML inferencing and training accelerator
EAPI=7
HOMEPAGE=https://github.com/microsoft/onnxruntime
INHERIT=cmake
IUSE=benchmark test
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=dev-python/numpy dev-libs/date:= >=dev-libs/boost-1.66:= dev-libs/protobuf:= dev-libs/re2:= dev-libs/flatbuffers:= dev-cpp/nlohmann_json:= dev-libs/nsync dev-cpp/eigen:3 benchmark? ( dev-cpp/benchmark )
RESTRICT=test
SLOT=0
SRC_URI=https://github.com/microsoft/onnxruntime/archive/refs/tags/v1.9.1.tar.gz -> onnxruntime-1.9.1.tar.gz https://github.com/pytorch/cpuinfo/archive/5916273f79a21551890fd3d56fc5375a78d1598d.tar.gz -> pytorch-cpuinfo-5916273f79.tar.gz https://github.com/onnx/onnx/archive/1f63dcb7fcc3a8bf5c3c8e326867ecd6f5c43f35.tar.gz -> onnx-1f63dcb7fc.tar.gz https://github.com/boostorg/mp11/archive/21cace4e574180ba64d9307a5e4ea9e5e94d3e8d.tar.gz -> boost_mp11-21cace4e574.tar.gz https://github.com/google/flatbuffers/archive/v1.12.0.tar.gz -> flatbuffers-1.12.0.tar.gz https://github.com/martinmoene/optional-lite/archive/4acf4553baa886e10e6613fe1452b706b0250e78.tar.gz -> optional-lite-4acf4553ba.tar.gz https://github.com/dcleblanc/SafeInt/archive/a104e0cf23be4fe848f7ef1f3e8996fe429b06bb.tar.gz -> SafeInt-a104e0cf23.tar.gz
_eclasses_=toolchain-funcs	fbbbc99d10168de2926e06da7169b8dc	multilib	c19072c3cd7ac5cb21de013f7e9832e0	flag-o-matic	5f250f8d967fc24a6490b549586670fa	multiprocessing	30ead54fa2e2b5f9cd4e612ffc34d0fe	ninja-utils	39e7a84b06eff4efd9f2e0c3d1668b98	xdg-utils	baea6080dd821f5562d715887954c9d3	cmake	fc2f89084f590ac95c004ea95b0d2f80
_md5_=1dba250e2b9b2b933724d6c7aa028105
